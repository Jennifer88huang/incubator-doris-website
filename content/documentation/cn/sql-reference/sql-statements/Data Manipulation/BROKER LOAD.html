

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>BROKER LOAD &mdash; Doris Documentations 0.11.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
    <link rel="next" title="CANCEL LOAD" href="CANCEL LOAD.html" />
    <link rel="prev" title="DML" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../../index.html" class="icon icon-home"> Doris Documentations
          

          
          </a>

          
            
            
              <div class="version">
                0.11.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../index.html">中文</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../downloads/index.html">下载</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../installing/index.html">编译与部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../getting-started/index.html">开始使用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../administrator-guide/index.html">操作手册</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../extending-doris/index.html">扩展功能</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../internal/index.html">设计文档</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html">SQL 手册</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../../sql-functions/index.html">SQL 函数</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../index.html">语法帮助</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../Account Management/index.html">用户账户管理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Administration/index.html">集群管理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Data Definition/index.html">DDL</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="index.html">DML</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Data Types/index.html">数据类型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Utility/index.html">辅助命令</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer-guide/index.html">开发者手册</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../community/index.html">Apache 社区</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../en/index.html">English</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">Doris Documentations</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../../index.html">中文</a> &raquo;</li>
        
          <li><a href="../../index.html">SQL 手册</a> &raquo;</li>
        
          <li><a href="../index.html">语法帮助</a> &raquo;</li>
        
          <li><a href="index.html">DML</a> &raquo;</li>
        
      <li>BROKER LOAD</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/apache/incubator-doris/blob/master/docs/documentation/cn/sql-reference/sql-statements/Data Manipulation/BROKER LOAD.md" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <!-- 
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
--><div class="section" id="broker-load">
<h1>BROKER LOAD<a class="headerlink" href="#broker-load" title="Permalink to this headline">¶</a></h1>
<div class="section" id="description">
<h2>description<a class="headerlink" href="#description" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Broker load 通过随 Doris 集群一同部署的 broker 进行，访问对应数据源的数据，进行数据导入。
可以通过 show broker 命令查看已经部署的 broker。
目前支持以下4种数据源：

1. Baidu HDFS：百度内部的 hdfs，仅限于百度内部使用。
2. Baidu AFS：百度内部的 afs，仅限于百度内部使用。
3. Baidu Object Storage(BOS)：百度对象存储。仅限百度内部用户、公有云用户或其他可以访问 BOS 的用户使用。
4. Apache HDFS：社区版本 hdfs。
5. Amazon S3：Amazon对象存储。
</pre></div>
</div>
<p>语法：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>LOAD LABEL load_label
(
data_desc1[, data_desc2, ...]
)
WITH BROKER broker_name
[broker_properties]
[opt_properties];

1. load_label

    当前导入批次的标签。在一个 database 内唯一。
    语法：
    [database_name.]your_label
 
2. data_desc

    用于描述一批导入数据。
    语法：
        DATA INFILE
        (
        &quot;file_path1&quot;[, file_path2, ...]
        )
        [NEGATIVE]
        INTO TABLE `table_name`
        [PARTITION (p1, p2)]
        [COLUMNS TERMINATED BY &quot;column_separator&quot;]
        [FORMAT AS &quot;file_type&quot;]
        [(column_list)]
        [SET (k1 = func(k2))]
        [WHERE predicate]    

    说明：
        file_path: 

        文件路径，可以指定到一个文件，也可以用 * 通配符指定某个目录下的所有文件。通配符必须匹配到文件，而不能是目录。

        PARTITION:

        如果指定此参数，则只会导入指定的分区，导入分区以外的数据会被过滤掉。
        如果不指定，默认导入table的所有分区。
    
        NEGATIVE：
        如果指定此参数，则相当于导入一批“负”数据。用于抵消之前导入的同一批数据。
        该参数仅适用于存在 value 列，并且 value 列的聚合类型仅为 SUM 的情况。
        
        column_separator：

        用于指定导入文件中的列分隔符。默认为 \t
        如果是不可见字符，则需要加\\x作为前缀，使用十六进制来表示分隔符。
        如hive文件的分隔符\x01，指定为&quot;\\x01&quot;
        
        file_type：

        用于指定导入文件的类型，例如：parquet、orc、csv。默认值通过文件后缀名判断。 

        column_list：

        用于指定导入文件中的列和 table 中的列的对应关系。
        当需要跳过导入文件中的某一列时，将该列指定为 table 中不存在的列名即可。
        语法：
        (col_name1, col_name2, ...)
        
        SET:

        如果指定此参数，可以将源文件某一列按照函数进行转化，然后将转化后的结果导入到table中。语法为 `column_name` = expression。举几个例子帮助理解。
        例1: 表中有3个列“c1, c2, c3&quot;, 源文件中前两列依次对应(c1,c2)，后两列之和对应c3；那么需要指定 columns (c1,c2,tmp_c3,tmp_c4) SET (c3=tmp_c3+tmp_c4); 
        例2: 表中有3个列“year, month, day&quot;三个列，源文件中只有一个时间列，为”2018-06-01 01:02:03“格式。
        那么可以指定 columns(tmp_time) set (year = year(tmp_time), month=month(tmp_time), day=day(tmp_time)) 完成导入。

        WHERE:
      
        对做完 transform 的数据进行过滤，符合 where 条件的数据才能被导入。WHERE 语句中只可引用表中列名。
3. broker_name

    所使用的 broker 名称，可以通过 show broker 命令查看。

4. broker_properties

    用于提供通过 broker 访问数据源的信息。不同的 broker，以及不同的访问方式，需要提供的信息不同。

    1. Baidu HDFS/AFS

        访问百度内部的 hdfs/afs 目前仅支持简单认证，需提供：
        username：hdfs 用户名
        password：hdfs 密码

    2. BOS

        需提供：
        bos_endpoint：BOS 的endpoint
        bos_accesskey：公有云用户的 accesskey
        bos_secret_accesskey：公有云用户的 secret_accesskey
    
    3. Apache HDFS

        社区版本的 hdfs，支持简单认证、kerberos 认证。以及支持 HA 配置。
        简单认证：
        hadoop.security.authentication = simple (默认)
        username：hdfs 用户名
        password：hdfs 密码

        kerberos 认证：
        hadoop.security.authentication = kerberos
        kerberos_principal：指定 kerberos 的 principal
        kerberos_keytab：指定 kerberos 的 keytab 文件路径。该文件必须为 broker 进程所在服务器上的文件。
        kerberos_keytab_content：指定 kerberos 中 keytab 文件内容经过 base64 编码之后的内容。这个跟 kerberos_keytab 配置二选一就可以。

        namenode HA：
        通过配置 namenode HA，可以在 namenode 切换时，自动识别到新的 namenode
        dfs.nameservices: 指定 hdfs 服务的名字，自定义，如：&quot;dfs.nameservices&quot; = &quot;my_ha&quot;
        dfs.ha.namenodes.xxx：自定义 namenode 的名字,多个名字以逗号分隔。其中 xxx 为 dfs.nameservices 中自定义的名字，如 &quot;dfs.ha.namenodes.my_ha&quot; = &quot;my_nn&quot;
        dfs.namenode.rpc-address.xxx.nn：指定 namenode 的rpc地址信息。其中 nn 表示 dfs.ha.namenodes.xxx 中配置的 namenode 的名字，如：&quot;dfs.namenode.rpc-address.my_ha.my_nn&quot; = &quot;host:port&quot;
        dfs.client.failover.proxy.provider：指定 client 连接 namenode 的 provider，默认为：org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider

    4. Amazon S3

        需提供：
        fs.s3a.access.key：AmazonS3的access key
        fs.s3a.secret.key：AmazonS3的secret key
        fs.s3a.endpoint：AmazonS3的endpoint 
    
4. opt_properties

    用于指定一些特殊参数。
    语法：
    [PROPERTIES (&quot;key&quot;=&quot;value&quot;, ...)]
    
    可以指定如下参数：
    timeout：         指定导入操作的超时时间。默认超时为4小时。单位秒。
    max_filter_ratio：最大容忍可过滤（数据不规范等原因）的数据比例。默认零容忍。
    exec_mem_limit：  导入内存限制。默认为 2GB。单位为字节。
    strict mode：     是否对数据进行严格限制。默认为 false。
    timezone:         指定某些受时区影响的函数的时区，如 strftime/alignment_timestamp/from_unixtime 等等，具体请查阅 [时区] 文档。如果不指定，则使用 &quot;Asia/Shanghai&quot; 时区。

5. 导入数据格式样例

    整型类（TINYINT/SMALLINT/INT/BIGINT/LARGEINT）：1, 1000, 1234
    浮点类（FLOAT/DOUBLE/DECIMAL）：1.1, 0.23, .356
    日期类（DATE/DATETIME）：2017-10-03, 2017-06-13 12:34:03。
    （注：如果是其他日期格式，可以在导入命令中，使用 strftime 或者 time_format 函数进行转换）
    字符串类（CHAR/VARCHAR）：&quot;I am a student&quot;, &quot;a&quot;
    NULL值：\N
</pre></div>
</div>
</div>
<div class="section" id="example">
<h2>example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. 从 HDFS 导入一批数据，指定超时时间和过滤比例。使用铭文 my_hdfs_broker 的 broker。简单认证。

    LOAD LABEL example_db.label1
    (
    DATA INFILE(&quot;hdfs://hdfs_host:hdfs_port/user/palo/data/input/file&quot;)
    INTO TABLE `my_table`
    )
    WITH BROKER my_hdfs_broker
    (
    &quot;username&quot; = &quot;hdfs_user&quot;,
    &quot;password&quot; = &quot;hdfs_passwd&quot;
    )
    PROPERTIES
    (
    &quot;timeout&quot; = &quot;3600&quot;,
    &quot;max_filter_ratio&quot; = &quot;0.1&quot;
    );

    其中 hdfs_host 为 namenode 的 host，hdfs_port 为 fs.defaultFS 端口（默认9000）

2. 从 AFS 一批数据，包含多个文件。导入不同的 table，指定分隔符，指定列对应关系。

    LOAD LABEL example_db.label2
    (
    DATA INFILE(&quot;afs://afs_host:hdfs_port/user/palo/data/input/file1&quot;)
    INTO TABLE `my_table_1`
    COLUMNS TERMINATED BY &quot;,&quot;
    (k1, k3, k2, v1, v2),
    DATA INFILE(&quot;afs://afs_host:hdfs_port/user/palo/data/input/file2&quot;)
    INTO TABLE `my_table_2`
    COLUMNS TERMINATED BY &quot;\t&quot;
    (k1, k2, k3, v2, v1)
    )
    WITH BROKER my_afs_broker
    (
    &quot;username&quot; = &quot;afs_user&quot;,
    &quot;password&quot; = &quot;afs_passwd&quot;
    )
    PROPERTIES
    (
    &quot;timeout&quot; = &quot;3600&quot;,
    &quot;max_filter_ratio&quot; = &quot;0.1&quot;
    );
    

3. 从 HDFS 导入一批数据，指定hive的默认分隔符\x01，并使用通配符*指定目录下的所有文件。
   使用简单认证，同时配置 namenode HA

    LOAD LABEL example_db.label3
    (
    DATA INFILE(&quot;hdfs://hdfs_host:hdfs_port/user/palo/data/input/*&quot;)
    INTO TABLE `my_table`
    COLUMNS TERMINATED BY &quot;\\x01&quot;
    )
    WITH BROKER my_hdfs_broker
    (
    &quot;username&quot; = &quot;hdfs_user&quot;,
    &quot;password&quot; = &quot;hdfs_passwd&quot;,
    &quot;dfs.nameservices&quot; = &quot;my_ha&quot;,
    &quot;dfs.ha.namenodes.my_ha&quot; = &quot;my_namenode1, my_namenode2&quot;,
    &quot;dfs.namenode.rpc-address.my_ha.my_namenode1&quot; = &quot;nn1_host:rpc_port&quot;,
    &quot;dfs.namenode.rpc-address.my_ha.my_namenode2&quot; = &quot;nn2_host:rpc_port&quot;,
    &quot;dfs.client.failover.proxy.provider&quot; = &quot;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&quot;
    )

4. 从 HDFS 导入一批“负”数据。同时使用 kerberos 认证方式。提供 keytab 文件路径。

    LOAD LABEL example_db.label4
    (
    DATA INFILE(&quot;hdfs://hdfs_host:hdfs_port/user/palo/data/input/old_file)
    NEGATIVE
    INTO TABLE `my_table`
    COLUMNS TERMINATED BY &quot;\t&quot;
    )
    WITH BROKER my_hdfs_broker
    (
    &quot;hadoop.security.authentication&quot; = &quot;kerberos&quot;,
    &quot;kerberos_principal&quot;=&quot;doris@YOUR.COM&quot;,
    &quot;kerberos_keytab&quot;=&quot;/home/palo/palo.keytab&quot;
    )

5. 从 HDFS 导入一批数据，指定分区。同时使用 kerberos 认证方式。提供 base64 编码后的 keytab 文件内容。

    LOAD LABEL example_db.label5
    (
    DATA INFILE(&quot;hdfs://hdfs_host:hdfs_port/user/palo/data/input/file&quot;)
    INTO TABLE `my_table`
    PARTITION (p1, p2)
    COLUMNS TERMINATED BY &quot;,&quot;
    (k1, k3, k2, v1, v2)
    )
    WITH BROKER my_hdfs_broker
    (
    &quot;hadoop.security.authentication&quot;=&quot;kerberos&quot;,
    &quot;kerberos_principal&quot;=&quot;doris@YOUR.COM&quot;,
    &quot;kerberos_keytab_content&quot;=&quot;BQIAAABEAAEACUJBSURVLkNPTQAEcGFsbw&quot;
    )

6. 从 BOS 导入一批数据，指定分区, 并对导入文件的列做一些转化，如下：
   表结构为：
    k1 varchar(20)
    k2 int

    假设数据文件只有一行数据：

    Adele,1,1

    数据文件中各列，对应导入语句中指定的各列：
    k1,tmp_k2,tmp_k3

    转换如下：

    1) k1: 不变换
    2) k2：是 tmp_k2 和 tmp_k3 数据之和

    LOAD LABEL example_db.label6
    (
    DATA INFILE(&quot;bos://my_bucket/input/file&quot;)
    INTO TABLE `my_table`
    PARTITION (p1, p2)
    COLUMNS TERMINATED BY &quot;,&quot;
    (k1, tmp_k2, tmp_k3)
    SET (
      k2 = tmp_k2 + tmp_k3
    )
    )
    WITH BROKER my_bos_broker
    (
    &quot;bos_endpoint&quot; = &quot;http://bj.bcebos.com&quot;,
    &quot;bos_accesskey&quot; = &quot;xxxxxxxxxxxxxxxxxxxxxxxxxx&quot;,
    &quot;bos_secret_accesskey&quot;=&quot;yyyyyyyyyyyyyyyyyyyy&quot;
    )

7. 导入数据到含有HLL列的表，可以是表中的列或者数据里面的列

    如果表中有三列分别是（id,v1,v2,v3）。其中v1和v2列是hll列。导入的源文件有3列。则（column_list）中声明第一列为id，第二三列为一个临时命名的k1,k2。
    在SET中必须给表中的hll列特殊声明 hll_hash。表中的v1列等于原始数据中的hll_hash(k1)列, 表中的v3列在原始数据中并没有对应的值，使用empty_hll补充默认值。
    LOAD LABEL example_db.label7
    (
    DATA INFILE(&quot;hdfs://hdfs_host:hdfs_port/user/palo/data/input/file&quot;)
    INTO TABLE `my_table`
    PARTITION (p1, p2)
    COLUMNS TERMINATED BY &quot;,&quot;
    (id, k1, k2)
    SET (
      v1 = hll_hash(k1),
      v2 = hll_hash(k2),
      v3 = empty_hll()
    )
    )
    WITH BROKER hdfs (&quot;username&quot;=&quot;hdfs_user&quot;, &quot;password&quot;=&quot;hdfs_password&quot;);

    LOAD LABEL example_db.label8
    (
    DATA INFILE(&quot;hdfs://hdfs_host:hdfs_port/user/palo/data/input/file&quot;)
    INTO TABLE `my_table`
    PARTITION (p1, p2)
    COLUMNS TERMINATED BY &quot;,&quot;
    (k1, k2, tmp_k3, tmp_k4, v1, v2)
    SET (
      v1 = hll_hash(tmp_k3),
      v2 = hll_hash(tmp_k4)
    )
    )
    WITH BROKER hdfs (&quot;username&quot;=&quot;hdfs_user&quot;, &quot;password&quot;=&quot;hdfs_password&quot;);

8. 导入Parquet文件中数据  指定FORMAT 为parquet， 默认是通过文件后缀判断

    LOAD LABEL example_db.label9
    (
    DATA INFILE(&quot;hdfs://hdfs_host:hdfs_port/user/palo/data/input/file&quot;)
    INTO TABLE `my_table`
    FORMAT AS &quot;parquet&quot;
    (k1, k2, k3)
    )
    WITH BROKER hdfs (&quot;username&quot;=&quot;hdfs_user&quot;, &quot;password&quot;=&quot;hdfs_password&quot;);

9. 提取文件路径中的分区字段

    如果需要，则会根据表中定义的字段类型解析文件路径中的分区字段（partitioned fields），类似Spark中Partition Discovery的功能

    LOAD LABEL example_db.label10
    (
    DATA INFILE(&quot;hdfs://hdfs_host:hdfs_port/user/palo/data/input/dir/city=beijing/*/*&quot;)
    INTO TABLE `my_table`
    FORMAT AS &quot;csv&quot;
    (k1, k2, k3)
    COLUMNS FROM PATH AS (city, utc_date)
    SET (uniq_id = md5sum(k1, city))
    )
    WITH BROKER hdfs (&quot;username&quot;=&quot;hdfs_user&quot;, &quot;password&quot;=&quot;hdfs_password&quot;);

    hdfs://hdfs_host:hdfs_port/user/palo/data/input/dir/city=beijing目录下包括如下文件：

    [hdfs://hdfs_host:hdfs_port/user/palo/data/input/dir/city=beijing/utc_date=2019-06-26/0000.csv, hdfs://hdfs_host:hdfs_port/user/palo/data/input/dir/city=beijing/utc_date=2019-06-26/0001.csv, ...]

    则提取文件路径的中的city和utc_date字段

10. 对待导入数据进行过滤，k1 值大于 k2 值的列才能被导入

    LOAD LABEL example_db.label10
    (
    DATA INFILE(&quot;hdfs://hdfs_host:hdfs_port/user/palo/data/input/file&quot;)
    INTO TABLE `my_table`
    where k1 &gt; k2
    )

11. 从 AmazonS3 导入Parquet文件中数据，指定 FORMAT 为parquet，默认是通过文件后缀判断：
    
    LOAD LABEL example_db.label11
    (
    DATA INFILE(&quot;s3a://my_bucket/input/file&quot;)
    INTO TABLE `my_table`
    FORMAT AS &quot;parquet&quot;
    (k1, k2, k3)
    )
    WITH BROKER my_s3a_broker
    (
    &quot;fs.s3a.access.key&quot; = &quot;xxxxxxxxxxxxxxxxxxxxxxxxxx&quot;,
    &quot;fs.s3a.secret.key&quot; = &quot;yyyyyyyyyyyyyyyyyyyy&quot;,
    &quot;fs.s3a.endpoint&quot; = &quot;s3.amazonaws.com&quot;
    )

12. 提取文件路径中的时间分区字段，并且时间包含 %3A (在 hdfs 路径中，不允许有 &#39;:&#39;，所有 &#39;:&#39; 会由 %3A 替换)

    假设有如下文件：

    /user/data/data_time=2020-02-17 00%3A00%3A00/test.txt
    /user/data/data_time=2020-02-18 00%3A00%3A00/test.txt

    表结构为：
    data_time DATETIME,
    k2        INT,
    k3        INT

    LOAD LABEL example_db.label12
    (
     DATA INFILE(&quot;hdfs://host:port/user/data/*/test.txt&quot;) 
     INTO TABLE `tbl12`
     COLUMNS TERMINATED BY &quot;,&quot;
     (k2,k3)
     COLUMNS FROM PATH AS (data_time)
     SET (data_time=str_to_date(data_time, &#39;%Y-%m-%d %H%%3A%i%%3A%s&#39;))
    ) 
    WITH BROKER &quot;hdfs&quot; (&quot;username&quot;=&quot;user&quot;, &quot;password&quot;=&quot;pass&quot;);
</pre></div>
</div>
</div>
<div class="section" id="keyword">
<h2>keyword<a class="headerlink" href="#keyword" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">BROKER</span><span class="p">,</span><span class="n">LOAD</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at
  http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->

<footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="CANCEL LOAD.html" class="btn btn-neutral float-right" title="CANCEL LOAD" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="DML" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Apache Doris(Incubating)

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
<div role="contentinfo">
    <p></p>
    <p>

        Apache Doris(incubating) is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.

    </p>
</div>


</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>