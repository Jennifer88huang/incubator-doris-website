(window.webpackJsonp=window.webpackJsonp||[]).push([[39],{428:function(e,t,a){"use strict";a.r(t);var s=a(43),o=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"statistics-of-query-execution"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#statistics-of-query-execution"}},[e._v("#")]),e._v(" Statistics of query execution")]),e._v(" "),a("p",[e._v("This document focuses on introducing the "),a("strong",[e._v("RuningProfle")]),e._v(" which recorded runtime status of Doris in query execution. Using these statistical information, we can understand the execution of frgment to become a expert of Doris's "),a("strong",[e._v("debugging and tuning")]),e._v(".")]),e._v(" "),a("h2",{attrs:{id:"noun-interpretation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#noun-interpretation"}},[e._v("#")]),e._v(" Noun Interpretation")]),e._v(" "),a("ul",[a("li",[a("p",[a("strong",[e._v("FE")]),e._v(": Frontend, frontend node of Doris. Responsible for metadata management and request access.")])]),e._v(" "),a("li",[a("p",[a("strong",[e._v("BE")]),e._v(": Backend, backend node of Doris. Responsible for query execution and data storage.")])]),e._v(" "),a("li",[a("p",[a("strong",[e._v("Fragment")]),e._v(": FE will convert the execution of specific SQL statements into corresponding fragments and distribute them to BE for execution. BE will execute corresponding fragments and gather the result of RunningProfile to send back FE.")])])]),e._v(" "),a("h2",{attrs:{id:"basic-concepts"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#basic-concepts"}},[e._v("#")]),e._v(" Basic concepts")]),e._v(" "),a("p",[e._v("FE splits the query plan into fragments and distributes them to BE for task execution. BE records the statistics of "),a("strong",[e._v("Running State")]),e._v(" when executing fragment. BE print the outputs statistics of fragment execution into the log. FE can also collect these statistics recorded by each fragment and print the results on FE's web page.")]),e._v(" "),a("h2",{attrs:{id:"specific-operation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#specific-operation"}},[e._v("#")]),e._v(" Specific operation")]),e._v(" "),a("p",[e._v("Turn on the report switch on FE through MySQL command")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("mysql> set is_report_success=true; \n")])])]),a("p",[e._v("After executing the corresponding SQL statement, we can see the report information of the corresponding SQL statement on the FE web page like the picture below.\n"),a("img",{attrs:{src:e.$withBase("https://upload-images.jianshu.io/upload_images/8552201-f5308be377dc4d90.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"),alt:"image.png"}})]),e._v(" "),a("p",[e._v("The latest  "),a("strong",[e._v("100 statements")]),e._v(" executed will be listed here. We can view detailed statistics of RunningProfile.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Query:\n  Summary:\n    Query ID: 9664061c57e84404-85ae111b8ba7e83a\n    Start Time: 2020-05-02 10:34:57\n    End Time: 2020-05-02 10:35:08\n    Total: 10s323ms\n    Query Type: Query\n    Query State: EOF\n    Doris Version: trunk\n    User: root\n    Default Db: default_cluster:test\n    Sql Statement: select max(Bid_Price) from quotes group by Symbol\n")])])]),a("p",[e._v("Here is a detailed list of  "),a("code",[e._v("query ID, execution time, execution statement")]),e._v(" and other summary information. The next step is to print the details of each fragment collected from be.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("   Fragment 0:\n     Instance 9664061c57e84404-85ae111b8ba7e83d (host=TNetworkAddress(hostname:10.144.192.47, port:9060)):(Active: 10s270ms, % non-child: 0.14%)\n        - MemoryLimit: 2.00 GB\n        - BytesReceived: 168.08 KB\n        - PeakUsedReservation: 0.00 \n        - SendersBlockedTimer: 0ns\n        - DeserializeRowBatchTimer: 501.975us\n        - PeakMemoryUsage: 577.04 KB\n        - RowsProduced: 8.322K (8322)\n       EXCHANGE_NODE (id=4):(Active: 10s256ms, % non-child: 99.35%)\n          - ConvertRowBatchTime: 180.171us\n          - PeakMemoryUsage: 0.00 \n          - RowsReturned: 8.322K (8322)\n          - MemoryUsed: 0.00 \n          - RowsReturnedRate: 811\n")])])]),a("p",[e._v("The fragment ID is listed here; "),a("code",[e._v("hostname")]),e._v(" show the be node executing the fragment; "),a("code",[e._v("active: 10s270ms")]),e._v("show the total execution time of the node;  "),a("code",[e._v("non child: 0.14%")]),e._v(" show the execution time of the node self except the execution time of the subchild node. Subsequently, the statistics of the child nodes will be printed in turn. "),a("strong",[e._v("here you can distinguish the parent-child relationship by intent")]),e._v(".")]),e._v(" "),a("h2",{attrs:{id:"profile-statistic-analysis"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#profile-statistic-analysis"}},[e._v("#")]),e._v(" Profile statistic analysis")]),e._v(" "),a("p",[e._v("There are many statistical information collected at BE.  so we list the corresponding meanings of profile are below:")]),e._v(" "),a("h4",{attrs:{id:"fragment"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#fragment"}},[e._v("#")]),e._v(" Fragment")]),e._v(" "),a("ul",[a("li",[e._v("AverageThreadTokens: Number of threads used to execute fragment, excluding the usage of thread pool")]),e._v(" "),a("li",[e._v("PeakReservation: Peak memory used by buffer pool")]),e._v(" "),a("li",[e._v("MemoryLimit: Memory limit at query")]),e._v(" "),a("li",[e._v("PeakMemoryUsage: Peak memory usage")]),e._v(" "),a("li",[e._v("RowsProduced: Number of rows that process")]),e._v(" "),a("li",[e._v("BytesReceived: Size of bytes received by network")]),e._v(" "),a("li",[e._v("DeserializeRowBatchTimer: Time consuming to receive data deserialization")])]),e._v(" "),a("h4",{attrs:{id:"datastreamsender"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#datastreamsender"}},[e._v("#")]),e._v(" DataStreamSender")]),e._v(" "),a("ul",[a("li",[e._v("BytesSent: Total bytes data sent")]),e._v(" "),a("li",[e._v("IgnoreRows: Rows filtered")]),e._v(" "),a("li",[e._v("OverallThroughput: Total throughput = BytesSent / Time")]),e._v(" "),a("li",[e._v("SerializeBatchTime: Sending data serialization time")]),e._v(" "),a("li",[e._v("UncompressedRowBatchSize: Size of rowbatch before sending data compression")])]),e._v(" "),a("h4",{attrs:{id:"sort-node"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sort-node"}},[e._v("#")]),e._v(" SORT_NODE")]),e._v(" "),a("ul",[a("li",[e._v("InMemorySortTime: In memory sort time")]),e._v(" "),a("li",[e._v("InitialRunsCreated: Number of initialize sort run")]),e._v(" "),a("li",[e._v("MergeGetNext: Time cost of MergeSort from multiple sort_run to get the next batch (only show spilled disk)")]),e._v(" "),a("li",[e._v("MergeGetNextBatch: Time cost MergeSort one sort_run to get the next batch (only show spilled disk)")]),e._v(" "),a("li",[e._v("SortDataSize: Total sorted data")]),e._v(" "),a("li",[e._v("TotalMergesPerformed: Number of external sort merges")])]),e._v(" "),a("h4",{attrs:{id:"aggregation-node："}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aggregation-node："}},[e._v("#")]),e._v(" AGGREGATION_NODE：")]),e._v(" "),a("ul",[a("li",[e._v("PartitionsCreated: Number of partition split by aggregate")]),e._v(" "),a("li",[e._v("GetResultsTime: Time to get aggregate results from each partition")]),e._v(" "),a("li",[e._v("HTResizeTime:  Time spent in resizing hashtable")]),e._v(" "),a("li",[e._v("HTResize:  Number of times hashtable resizes")]),e._v(" "),a("li",[e._v("HashBuckets: Number of buckets in hashtable")]),e._v(" "),a("li",[e._v("HashBucketsWithDuplicate:  Number of buckets with duplicatenode in hashtable")]),e._v(" "),a("li",[e._v("HashCollisions:  Number of hash conflicts generated")]),e._v(" "),a("li",[e._v("HashDuplicateNodes:  Number of duplicate nodes with the same buckets in hashtable")]),e._v(" "),a("li",[e._v("HashFailedProbe:  Number of failed probe operations")]),e._v(" "),a("li",[e._v("HashFilledBuckets:  Number of buckets filled data")]),e._v(" "),a("li",[e._v("HashProbe:  Number of hashtable probe")]),e._v(" "),a("li",[e._v("HashTravelLength:  The number of steps moved when hashtable queries")])]),e._v(" "),a("h4",{attrs:{id:"olap-scan-node"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#olap-scan-node"}},[e._v("#")]),e._v(" OLAP_SCAN_NODE:")]),e._v(" "),a("ul",[a("li",[e._v("BytesRead: Total data")]),e._v(" "),a("li",[e._v("TotalReadThroughput：Throughput = BytesRead / Time")]),e._v(" "),a("li",[e._v("TabletCount: Number of scanned tablets")]),e._v(" "),a("li",[e._v("RowsPushedCondFiltered：Number of filters pushed down")]),e._v(" "),a("li",[e._v("RawRowsRead: Number of rows read")]),e._v(" "),a("li",[e._v("RowsReturned: Number of rows returned by the node")]),e._v(" "),a("li",[e._v("RowsReturnedRate: Rate of rows returned")]),e._v(" "),a("li",[e._v("PeakMemoryUsage: Peak memory usage of the node")])]),e._v(" "),a("h4",{attrs:{id:"buffer-pool"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#buffer-pool"}},[e._v("#")]),e._v(" Buffer pool:")]),e._v(" "),a("ul",[a("li",[e._v("AllocTime: Memory allocation time")]),e._v(" "),a("li",[e._v("CumulativeAllocationBytes: Cumulative amount of memory allocated")]),e._v(" "),a("li",[e._v("CumulativeAllocations: Cumulative number of memory allocations")]),e._v(" "),a("li",[e._v("PeakReservation: Peak of reservation")]),e._v(" "),a("li",[e._v("PeakUnpinnedBytes: Amount of memory data of unpin")]),e._v(" "),a("li",[e._v("PeakUsedReservation: Peak usage of reservation")]),e._v(" "),a("li",[e._v("ReservationLimit: Limit of reservation of bufferpool")])])])}),[],!1,null,null,null);t.default=o.exports}}]);